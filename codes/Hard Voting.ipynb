{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vote on predictions from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from keras import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, auc, classification_report, confusion_matrix, balanced_accuracy_score, roc_curve, roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Train_Images'\n",
    "val_dir = 'Val_Images'\n",
    "test_dir = 'Test_Images'\n",
    "#number of classes\n",
    "num_classes = 2\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Weights from different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = keras.models.load_model('Models/Vgg19_All_Limbs.h5')\n",
    "resnet152_v2 = keras.models.load_model('Models/Resnet152_All_Limbs.h5')\n",
    "mobilenet = keras.models.load_model('Models/Mobilenet_All_Limbs.h5')\n",
    "inception_v3 = keras.models.load_model('Models/Inception_V3_All_Limbs.h5')\n",
    "densenet = keras.models.load_model('Models/Densenet169_All_Limbs.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Defination for General Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_subset = sorted(os.listdir('Test_Images'), reverse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator as per the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255\n",
    "                                                            )\n",
    "test_ds = test_gen.flow_from_directory(test_dir,\n",
    "                                        target_size=(img_height, img_width),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='sparse',\n",
    "                                        shuffle=False,\n",
    "                                        classes=['Intact','Fractured'],\n",
    "                                        seed=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes = test_ds.classes\n",
    "class_indices = {'Intact': 0, 'Fractured': 1}\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "prediction_vgg19 = vgg19.predict(test_ds)\n",
    "pred_classes_vgg19 = np.argmax(prediction_vgg19, axis=1) \n",
    "pred_classes_vgg19\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes = test_ds.classes\n",
    "class_indices = {'Intact': 0, 'Fractured': 1}\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "prediction_resnet152 = resnet152_v2.predict(test_ds)\n",
    "pred_classes_resnet152 = np.argmax(prediction_resnet152, axis=1) \n",
    "pred_classes_resnet152 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes = test_ds.classes\n",
    "class_indices = {'Intact': 0, 'Fractured': 1}\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "prediction_inception = inception_v3.predict(test_ds)\n",
    "pred_classes_inception = np.argmax(prediction_inception, axis=1) \n",
    "pred_classes_inception "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes = test_ds.classes\n",
    "class_indices = {'Intact': 0, 'Fractured': 1}\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "prediction_densenet = mobilenet.predict(test_ds)\n",
    "pred_classes_densenet = np.argmax(prediction_densenet, axis=1) \n",
    "pred_classes_densenet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes = test_ds.classes\n",
    "class_indices = {'Intact': 0, 'Fractured': 1}\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "prediction_mobilenet = densenet.predict(test_ds)\n",
    "pred_classes_mobilenet = np.argmax(prediction_mobilenet, axis=1) \n",
    "pred_classes_mobilenet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Prediction Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_preds = [pred_classes_vgg19, pred_classes_resnet152, pred_classes_inception, pred_classes_mobilenet, pred_classes_densenet]\n",
    "voted_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), 0, np.array(combined_preds))\n",
    "voted_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrices for the combined Predictionss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the true class values of the images, any datagenerator could be used\n",
    "true_classes = test_ds.classes\n",
    "true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, auc, classification_report, confusion_matrix, balanced_accuracy_score, roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "\n",
    "#calculating each of the metrices\n",
    "accuracy = accuracy_score(true_classes, voted_preds)\n",
    "balanced_accuracy = balanced_accuracy_score(true_classes, voted_preds)\n",
    "\n",
    "precision = precision_score(true_classes, voted_preds)\n",
    "f1 = f1_score(true_classes, voted_preds)\n",
    "\n",
    "recall = recall_score(true_classes, voted_preds)\n",
    "\n",
    "auc_mod = roc_auc_score(true_classes, voted_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy After Voting on Test Datset: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Balanced Accuracy After Voting on Test Datset: {:.2f}%\".format(balanced_accuracy * 100))\n",
    "print(\"Precision  After Voting on Test Datset: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall  After Voting on Test Datset: {:.2f}%\".format(recall * 100))\n",
    "print(\"F1-Score After Voting on Test Datset: {:.2f}%\".format(f1 * 100))\n",
    "\n",
    "\n",
    "#dictionary of the metrices\n",
    "metrices = {'Accuracy' : [accuracy], 'Balanced_Accuracy': [balanced_accuracy], 'Precision': [precision], 'Recall': [recall], 'F1_Score': [f1], 'auc': auc_mod}\n",
    "\n",
    "#create a dataframe of the metrices\n",
    "df = pd.DataFrame.from_dict(metrices, orient='columns', dtype=None, columns=None)\n",
    "\n",
    "#check for the file for saving metrices\n",
    "file_save_path = 'Graphs/' + 'Voted_Result' + '/'\n",
    "file_save_name = file_save_path + 'Voted_Result' + '_' + 'All_Limbs' +'_metrices.csv'\n",
    "\n",
    "#check for the folder path, if exists skip else create the path\n",
    "if not (os.path.exists(file_save_path)):\n",
    "    os.makedirs(file_save_path)\n",
    "\n",
    "df.to_csv(file_save_name, index=None)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap for Combined Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(true_classes, voted_preds)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax = sns.heatmap(conf_mat, annot=True, cbar=False, square=True, fmt='d', cmap=plt.cm.Blues, xticklabels=class_subset, yticklabels=class_subset,annot_kws={'size': 18})\n",
    "heatmap = ax.get_figure()\n",
    "\n",
    "#check for the file for saving heatmap\n",
    "figure_save_path = 'Graphs/' + 'Voted_Result' + '/'\n",
    "figure_save_name = figure_save_path + 'Voted_Result' + '_' + 'All_Limbs' +'_combined_confusion_matrix.jpg'\n",
    "\n",
    "#check for the folder path, if exists skip else create the path\n",
    "if not (os.path.exists(figure_save_path)):\n",
    "    os.makedirs(figure_save_path)\n",
    "\n",
    "heatmap.savefig(figure_save_name, dpi=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mismatched classification after combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_wrong = []\n",
    "\n",
    "for i, file in enumerate(test_ds.filenames):\n",
    "    if voted_preds[i]!=true_classes[i]:\n",
    "        combined_wrong.append(file)\n",
    "combined_wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43318353f1a0791341fbda672d4b2e4730d19aa1ad193afffab4fb3bc1431d4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
